TITLE+: TinyML as-a-Service architecture
AUTHOR+: Hiroshi Doyu

TinyMLaaS is just a thin REST API server,
which backend would call a specified docker image,
to generate an OS image.
Those docker images are expected to be provided by partners.
The installation of those generaete OS images are done via LwM2M FOTA
with an URL to an OS image.


* Implement TinyMLaaS
TinyMLaaS is a REST API server. This server side stub is
automatically generated by [[https://www.openapis.org/][Open API Specification]] (OAS) file,
hosted by [[https://swagger.io/tools/swaggerhub/][Swagger HUB]]. This also could generate client side code too.
The backend of TinyMLaaS server would simply run the specified docker image,
stored in [[https://hub.docker.com/][DockerHUB]]. This docker image accepts some parameteres passed
via REST. For example, target device type and inference model name.
Probably Go would be the generated stub
since it may be easier to call docker API later
to run a docker image.

[[./images/arch.png]]


* Build OS image
OS build procedure is packed in a docker image.
If you pull and run this docker image, it would generate a new OS image,
which include a specified inference model.
Those docker images are provided by partner companies.
Those docker images are stored in [[https://hub.docker.com/][DockerHUB]].
We'll support a limitted number of target boards.
OS image should include LwM2M client and FOTA.
A generated OS images are stored in TinyMLaaS.
It could be downloaded by http.

[[./images/arch_001.png]]


* Update OS image
LwM2M FOTA would replace a whole OS image with updated interence model.
Leshan server(LwM2M server) has pulished a REST API for FOTA.
A client would trigger FOTA via the above Leshan REST API for FOTA.
There's no implementation work here.

[[./images/arch_002.png]]
