#+TITLE: [[https://sched.co/TLCJ][TinyML as-a-Service:]] Backend Porting Guide
#+AUTHOR: [[hiroshi.doyu@ericsson.com][Hiroshi Doyu]] <hiroshi.doyu@ericsson.com>
#+EMAIL: hiroshi.doyu@ericsson.com

* Design
TinyML as-a-Service (TinyMLaaS) would demonstrate ML inference orchestration
on IoT devices.
TinyMLaaS is just a thin REST API server, based on [[https://swagger.io/tools/swagger-ui/][Swagger UI]],
which backend would run a requested docker image
to build an device OS image on server. Conceptually it's similar to [[https://www.openfaas.com/][OpenFaaS]].
Each API call is equivalent to run a centain docker image on server.
Those docker images would compile ML inference and
then generate an device OS image with ML inference in it.
Pre-trained ML inference models are stored in model **Zoo** archive on Cloud.
Those OS build docker images are expected to be provided
by 3rd party partners (AI chip/ML compiler vendors).
The installation of those generaeted device OS images onto devices is done
via [[https://www.omaspecworks.org/what-is-oma-specworks/iot/lightweight-m2m-lwm2m/][OMA LwM2M]] [[https://foundries.io/insights/2018/01/17/20180117-lwm2m-update/][FOTA]] (Firmware Other The Air) update
with an URL pointing to an OS image stored on TinyMLaaS,
as seen in Figure 1.

** 4 main components
This document will explain
how TinyMLaaS is to be developed independently by different entities.
TinyMLaaS includes 4 components:

1. Web App
2. API server
3. device OS builder (+ML compiler)
4. device OS downloader (LwM2M FOTA)

For partner to implement backend,
only "3. device OS builder (+ML compiler)" is needed.

#+CAPTION: TinyML components
[[./images/arch.png]]


* Web App (TBD)
This is a Frontend GUI for users.
Once API servier (backend) is implemented,
both Web App (+Mobile App?) could be implemented just by calling those REST API.
Web App could provide nice UI for demonstration, but this could be done later.
since all REST API can be called via [[https://swagger.io/tools/swagger-ui/][Swagger UI]].
Test could be done via [[https://swagger.io/tools/swagger-ui/][Swagger UI]] without Web App.

* API server (Ericsson)
TinyMLaaS is a REST API server. This server side stub is
automatically generated by [[https://www.openapis.org/][Open API Specification]] (OAS) file,
hosted by [[https://swagger.io/tools/swaggerhub/][Swagger HUB]]. This also could generate client side code too if needed.
The backend of API server would simply run the specified docker image,
stored in [[https://hub.docker.com/][DockerHUB]]. This docker image accepts some parameteres passed
via REST. For example, target device type and inference model name.
Some appropriate docker API via Unix domain socket is called
to run a docker image. Please refer to Figure 2.

#+CAPTION: API server
[[./images/arch_001.png]]


* device OS builder (Partner)
This is the part which partner needs to implement.
OS build procedure is packed in a docker image.
If you pull and run this docker image, it would generate a new OS image,
which include a specified ML inference model.
Those docker images are provided by partner companies.
Those docker images are stored in [[https://hub.docker.com/][DockerHUB]].
We'll support a limitted number of target boards.
OS should support LwM2M client and its FOTA feature to reflash OS image.
Some of popular RTOSes support LwM2M with FOTA (FreeRTOS?).
LwM2M FOTA is the specification of CoAP protocol,
but it doesn't define how to flash OS image and how to reboot a device.
Those need to be implemented here.
A generated OS images are stored in TinyMLaaS.
It could be downloaded by http from LwM2M server later.
docker image should be run independently and
generate OS image with ML inference locally on your host.
 Please refer to Figure 3.

** docker commands to support for unit testing
#+BEGIN_SRC shell
$ docker build -t esp32_wroover .
$ docker run esp32_wroover mnist.model
$ docker upload esp32_wroover
#+END_SRC

** 4 sub-components to implement
To summarize, the following 3 needs to be implemented.
1. ML compiler in docker
2. OS builder in docker
3. LwM2M client in OS
4. OS updator
"1" and "2" can be in a single docker image.

#+CAPTION: device OS builder
[[./images/arch_002.png]]


* device OS downloader (LwM2M FOTA)
LwM2M FOTA would replace a whole OS image with updated ML interence model.
Leshan server(LwM2M server) has published a REST API for FOTA.
A client would trigger FOTA via the above Leshan REST API for FOTA.
How to flash OS image and how to reboot a device are implemented
in the previous device OS builder phase.
There's no implementation work here.
Please refer to Figure 4.

#+CAPTION: device OS updator
[[./images/arch_003.png]]


* Use case
This demo is mainly about ML inferece orchestration.
Use case depends highly on the feature of target boards partner use.
Please provide the following info:

1. Which target boards to use?
2. Which ML inferences to replace?
3. What kind of use case scenario?

If you have any questions, don't hesiate to ask any questions.
